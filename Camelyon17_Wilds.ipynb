{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN2q+p1cNAksxZzn9l+2Zbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnesAgirman/ArUco_Markers/blob/main/Camelyon17_Wilds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCwMj-arFf1B",
        "outputId": "8f20bbdb-282c-47fd-9943-0cc86c30b0ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1solB9Kf3QC4"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 1: Install dependencies ─────────────────────────────────────────────\n",
        "!pip install --quiet wilds torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2: Imports & Dataset ────────────────────────────────────────────────\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from wilds import get_dataset\n",
        "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torch.optim import SGD, Adam, RMSprop\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 2048\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "try:\n",
        "    mp.set_start_method(\"spawn\", force=True)\n",
        "except RuntimeError:\n",
        "    pass  # already set\n",
        "\n",
        "# Download (or reuse) into WILDS’s cache automatically\n",
        "dataset = get_dataset(\n",
        "    dataset=\"camelyon17\",\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# ✅ Add standard normalization (ImageNet stats) to help training stability\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std =[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create train/val/test splits\n",
        "train_ds = dataset.get_subset(\"train\", transform=transform)\n",
        "val_ds   = dataset.get_subset(\"val\",   transform=transform)\n",
        "test_ds  = dataset.get_subset(\"test\",  transform=transform)\n",
        "\n",
        "# Wrap in standard loaders (shuffled for baseline, used by other trainers)\n",
        "train_loader = get_train_loader(\"standard\", train_ds, batch_size=batch_size)\n",
        "val_loader   = get_eval_loader (\"standard\", val_ds,   batch_size=batch_size)\n",
        "test_loader  = get_eval_loader (\"standard\", test_ds,  batch_size=batch_size)\n",
        "\n",
        "# empirical uniform distribution over the N samples (RS uses its own P_hat)\n",
        "N = len(train_ds)\n",
        "P_hat = torch.full((N,), 1.0/N, device=device)\n",
        "\n",
        "class IndexedDataset(Dataset):\n",
        "    \"\"\"Returns (x, y, idx) instead of (x, y, meta).\"\"\"\n",
        "    def __init__(self, subset):\n",
        "        self.subset = subset\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y, _ = self.subset[idx]\n",
        "        return x, y, idx\n",
        "\n",
        "# RS needs a loader *without* shuffling so idx→position stays consistent\n",
        "rs_loader = DataLoader(\n",
        "    IndexedDataset(train_ds),\n",
        "    batch_size=512,                  # try 1024; 512 if CPU is slow, 2048 if CPU is strong\n",
        "    shuffle=False,\n",
        "    num_workers=min(12, os.cpu_count() or 4),\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,          # keeps workers alive between epochs\n",
        "    prefetch_factor=4,                # prefetches per worker\n",
        ")\n"
      ],
      "metadata": {
        "id": "dTz6ymnH5HLe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3 ────────────────────────────────────────────────\n",
        "\n",
        "# Simplified model\n",
        "\"\"\"\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=None, num_classes=2)\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\"\"\"\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)  # 96x96 → 96x96\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)                                 # 96x96 → 48x48\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)                          # 48x48 → 48x48\n",
        "        # After pooling again: 48x48 → 24x24\n",
        "        self.fc1 = nn.Linear(32 * 24 * 24, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))   # 96x96 → 48x48\n",
        "        x = self.pool(F.relu(self.conv2(x)))   # 48x48 → 24x24\n",
        "        x = x.view(x.size(0), -1)              # Flatten (B, 32*24*24)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Projection onto simplex\n",
        "def proj_simplex(v):\n",
        "    if v.dim() != 1:\n",
        "        raise ValueError(\"proj_simplex expects a 1-D tensor\")\n",
        "    # From: https://arxiv.org/pdf/1101.6081.pdf\n",
        "    u, _ = torch.sort(v, descending=True)\n",
        "    cssv = torch.cumsum(u, 0) - 1\n",
        "    ind = torch.arange(1, v.numel() + 1, device=v.device, dtype=v.dtype)\n",
        "    t = cssv / ind\n",
        "    support = u > t\n",
        "    if not support.any():\n",
        "        return torch.full_like(v, 1.0 / v.numel())\n",
        "    rho = torch.nonzero(support, as_tuple=False).max()\n",
        "    theta = t[rho]\n",
        "    w = torch.clamp(v - theta, min=0.0)\n",
        "    return w\n",
        "\n",
        "\n",
        "class KappaFunctionImproved(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, F, P_hat, tau, distance_scale, min_divergence,\n",
        "                softplus_temp=2.0, neg_scale=0.1, h_max=0.5):\n",
        "        # a = E_{P_hat}[F], b = ||F||^2\n",
        "        a = torch.dot(F, P_hat)\n",
        "        b = torch.clamp(torch.sum(F * F), min=1e-12)\n",
        "        num = tau - a\n",
        "        # ✅ clamp h to avoid extreme steps when b is tiny\n",
        "        h = torch.clamp(num / b, min=-h_max, max=h_max)  # scalar\n",
        "\n",
        "        w_vec = P_hat + h * F\n",
        "        P_star = proj_simplex(w_vec)\n",
        "\n",
        "        diff = P_star - P_hat\n",
        "        D_base = 0.5 * torch.sum(diff * diff)\n",
        "        D_eff = distance_scale * D_base + min_divergence\n",
        "\n",
        "        E_f = torch.dot(P_star, F)\n",
        "        raw_kappa = (E_f - tau) / D_eff\n",
        "\n",
        "        # activation: positive via tempered softplus, negative shrunk\n",
        "        pos = torch.nn.functional.softplus(raw_kappa / softplus_temp) * softplus_temp\n",
        "        neg = raw_kappa * neg_scale\n",
        "        kappa = torch.where(raw_kappa >= 0, pos, neg)\n",
        "\n",
        "        ctx.save_for_backward(F, P_hat, P_star, raw_kappa,\n",
        "                              torch.tensor(distance_scale, device=F.device, dtype=F.dtype),\n",
        "                              torch.tensor(min_divergence, device=F.device, dtype=F.dtype),\n",
        "                              torch.tensor(softplus_temp, device=F.device, dtype=F.dtype),\n",
        "                              torch.tensor(neg_scale, device=F.device, dtype=F.dtype),\n",
        "                              torch.tensor(h_max, device=F.device, dtype=F.dtype))\n",
        "        ctx.tau = tau\n",
        "        return kappa, raw_kappa  # return raw for diagnostics\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out_kappa, grad_out_raw_unused=None):\n",
        "        (F, P_hat, P_star, raw_kappa,\n",
        "         distance_scale_t, min_div_t, temp_t, neg_scale_t, hmax_t) = ctx.saved_tensors\n",
        "        distance_scale = float(distance_scale_t.item())\n",
        "        min_divergence = float(min_div_t.item())\n",
        "        softplus_temp  = float(temp_t.item())\n",
        "        neg_scale      = float(neg_scale_t.item())\n",
        "        h_max          = float(hmax_t.item())\n",
        "        tau            = ctx.tau\n",
        "\n",
        "        diff = P_star - P_hat\n",
        "        D_base = 0.5 * torch.sum(diff * diff)\n",
        "        D_eff = distance_scale * D_base + min_divergence\n",
        "\n",
        "        E_f = torch.dot(P_star, F)\n",
        "        a = torch.dot(F, P_hat)\n",
        "        b = torch.clamp(torch.sum(F * F), min=1e-12)\n",
        "        num = tau - a\n",
        "        # ✅ keep consistent with forward\n",
        "        h = torch.clamp(num / b, min=-h_max, max=h_max)\n",
        "\n",
        "        grad_b = 2.0 * F\n",
        "\n",
        "        # Projection Jacobian on active support (simplex proj, local linearization)\n",
        "        support = P_star > 0\n",
        "        def apply_J_proj(u):\n",
        "            u_s = u[support]\n",
        "            if u_s.numel() == 0:\n",
        "                return torch.zeros_like(u)\n",
        "            mean_s = u_s.mean()\n",
        "            out = torch.zeros_like(u)\n",
        "            out[support] = u_s - mean_s\n",
        "            return out\n",
        "\n",
        "        t = apply_J_proj(F)      # dP*/d(h*F) · F\n",
        "        s = apply_J_proj(diff)   # dP*/d(P*) · (P* - P_hat)  (heuristic)\n",
        "\n",
        "        Ft = torch.dot(F, t)\n",
        "        Fs = torch.dot(F, s)\n",
        "\n",
        "        # dh/dF via implicit differentiation of h = (tau - a)/b (with clamp ignored in grad)\n",
        "        grad_h = (-b * P_hat - num * grad_b) / (b * b)\n",
        "\n",
        "        A = P_star + h * t + grad_h * Ft\n",
        "        B = h * s + grad_h * Fs\n",
        "\n",
        "        numerator = A * D_eff - (E_f - tau) * B\n",
        "        grad_raw_kappa = numerator / (D_eff * D_eff)\n",
        "\n",
        "        sigmoid_part = torch.sigmoid(raw_kappa / softplus_temp)\n",
        "        grad_activation = torch.where(raw_kappa >= 0, sigmoid_part,\n",
        "                                      torch.full_like(sigmoid_part, neg_scale))\n",
        "        grad_kappa_wrt_raw = grad_activation\n",
        "\n",
        "        grad_raw = grad_out_kappa * grad_kappa_wrt_raw\n",
        "        grad_F = grad_raw * grad_raw_kappa\n",
        "\n",
        "        return grad_F, None, None, None, None, None, None, None, None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zuJV-njQ4LnO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 4: Train & Eval Helpers ─────────────────────────────────────────────\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y, _ in tqdm(loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            preds = model(x).argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def evaluate_with_diagnostics(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(y.cpu())\n",
        "    preds = torch.cat(all_preds).tolist()\n",
        "    labels = torch.cat(all_labels).tolist()\n",
        "    acc = correct / total if total > 0 else 0.0\n",
        "    print(f\"[Eval] Accuracy: {acc:.4f}\")\n",
        "    print(\"Prediction distribution:\", Counter(preds))\n",
        "    print(\"True label distribution:\", Counter(labels))\n",
        "    cm = torch.zeros(2, 2, dtype=torch.int64)\n",
        "    for p, t in zip(preds, labels):\n",
        "        cm[t, p] += 1  # row=true, col=pred\n",
        "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n",
        "    return acc\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def evaluate_with_diagnostics(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(y.cpu())\n",
        "    preds = torch.cat(all_preds).tolist()\n",
        "    labels = torch.cat(all_labels).tolist()\n",
        "    acc = correct / total if total > 0 else 0.0\n",
        "    print(f\"[Eval] Accuracy: {acc:.4f}\")\n",
        "    print(\"Prediction distribution:\", Counter(preds))\n",
        "    print(\"True label distribution:\", Counter(labels))\n",
        "    cm = torch.zeros(2, 2, dtype=torch.int64)\n",
        "    for p, t in zip(preds, labels):\n",
        "        cm[t, p] += 1  # row=true, col=pred\n",
        "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n",
        "    return acc\n",
        "\n",
        "\n",
        "# --- Comparison baselines (optional) ---\n",
        "def train_standard(model, loader, epochs, lr):\n",
        "    model.to(device)\n",
        "    opt = SGD(model.parameters(), lr=lr)\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            opt.zero_grad()\n",
        "            loss = ce(model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.item() * x.size(0)\n",
        "        avg = total / len(loader.dataset)\n",
        "        losses.append(avg)\n",
        "        print(f\"[SGD] Epoch {ep+1}/{epochs} CE loss: {avg:.4f}\", flush=True)\n",
        "    return losses\n",
        "\n",
        "def train_sam(model, loader, epochs, lr, rho=0.05):\n",
        "    model.to(device)\n",
        "    base_opt = SGD\n",
        "    optimizer = base_opt(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            grad_norm = torch.norm(torch.stack([p.grad.norm() for p in model.parameters() if p.grad is not None]))\n",
        "            scale = rho / (grad_norm + 1e-12)\n",
        "            e_ws = []\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is None:\n",
        "                        e_ws.append(None)\n",
        "                        continue\n",
        "                    e_w = p.grad * scale\n",
        "                    p.add_(e_w)\n",
        "                    e_ws.append(e_w)\n",
        "            optimizer.zero_grad()\n",
        "            logits2 = model(x)\n",
        "            loss2 = criterion(logits2, y)\n",
        "            loss2.backward()\n",
        "            with torch.no_grad():\n",
        "                for p, e_w in zip(model.parameters(), e_ws):\n",
        "                    if e_w is not None:\n",
        "                        p.sub_(e_w)\n",
        "            optimizer.step()\n",
        "            total += loss2.item() * x.size(0)\n",
        "        avg = total / len(loader.dataset)\n",
        "        losses.append(avg)\n",
        "        print(f\"[SAM] Epoch {ep+1}/{epochs} CE loss: {avg:.4f}\", flush=True)\n",
        "    return losses\n"
      ],
      "metadata": {
        "id": "qHBrIemB4GyV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_rs(\n",
        "    model,\n",
        "    rs_loader,\n",
        "    epochs,\n",
        "    lr=2e-5,\n",
        "    initial_tau_multiplier=0.8,\n",
        "    tau_target_multiplier=0.9,\n",
        "    tau_smooth_lr=0.3,\n",
        "    P_hat_momentum=0.3,\n",
        "    damp_surrogate=0.1,\n",
        "    ce_reg_weight=0.1,\n",
        "    warmup_ce_weight=1.0,\n",
        "    entropy_reg_weight=0.01,\n",
        "    use_subset=False,\n",
        "    subset_size=2048,\n",
        "    normalize_w=False,\n",
        "    debug=False,\n",
        "    base_tau=0.1,\n",
        "    distance_scale=1.0,\n",
        "    softplus_temp=2.0,\n",
        "    warmup_epochs=5,\n",
        "    kappa_shrink_threshold=1e3,\n",
        "    tau_smooth_lr_boost=2.0,\n",
        "    neg_scale=0.1,\n",
        "    start_at_base=False,\n",
        "    fixed_tau=False,\n",
        "    val_loader=None,\n",
        "    val_interval=5,\n",
        "    early_stop_patience=3,\n",
        "    min_epochs_before_early_stop=5,\n",
        "    negative_kappa_damping=0.1,\n",
        "    shrink_factor_on_approx_violation=0.7,\n",
        "    shrink_tau_on_zero_kappa=True,\n",
        "    zero_kappa_decay_factor=0.95,\n",
        "    # NEW stabilizers:\n",
        "    h_max=0.5,\n",
        "    min_div_from_var_scale=1e-2,\n",
        "    min_div_floor=1e-4,\n",
        "    stratify_seed=123,\n",
        "    # NEW quality-of-life:\n",
        "    F_eval_fraction=1.0,   # 1.0 = full pass; use 0.25 to debug faster\n",
        "):\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    ce_element = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    # --- subset handling (unchanged) ---\n",
        "    if use_subset:\n",
        "        ...\n",
        "        # (leave your existing subset code unchanged)\n",
        "    else:\n",
        "        active_loader = rs_loader\n",
        "        N = len(rs_loader.dataset)\n",
        "\n",
        "    # initialize P_hat\n",
        "    P_hat = torch.full((N,), 1.0 / N, device=device)\n",
        "\n",
        "    # ✅ show we’re about to compute F (this can take time on full data)\n",
        "    est_batches = ceil((N * F_eval_fraction) / active_loader.batch_size)\n",
        "    print(f\"[RS] Computing F on {F_eval_fraction*100:.0f}% of training data \"\n",
        "          f\"({int(N*F_eval_fraction)}/{N}) ~{est_batches} batches...\", flush=True)\n",
        "\n",
        "    def compute_F(model, loader, fraction=1.0, desc=\"F pass\"):\n",
        "        \"\"\"Compute per-example CE losses for a fraction of the dataset, with progress.\"\"\"\n",
        "        model.eval()\n",
        "        take_items = int(len(loader.dataset) * fraction)\n",
        "        if take_items <= 0:\n",
        "            take_items = len(loader.dataset)\n",
        "        # progress bar\n",
        "        F_cpu = torch.zeros(len(loader.dataset), device='cpu')\n",
        "        seen = 0\n",
        "        for x, y, idx in tqdm(loader, total=ceil(take_items/loader.batch_size), desc=desc, leave=False):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                losses = ce_element(model(x), y).cpu()\n",
        "            F_cpu[idx] = losses\n",
        "            seen += x.size(0)\n",
        "            if seen >= take_items:\n",
        "                break\n",
        "        return F_cpu.to(device)\n",
        "\n",
        "    # initial values (now with progress)\n",
        "    F_vals = compute_F(model, active_loader, fraction=F_eval_fraction, desc=\"F (init)\").clone().requires_grad_(True)\n",
        "    E_f = torch.dot(P_hat, F_vals).item()\n",
        "    ef_ema = E_f\n",
        "    if start_at_base:\n",
        "        tau = base_tau\n",
        "    else:\n",
        "        tau = max(base_tau, initial_tau_multiplier * E_f)\n",
        "    print(f\"[RS init] N={N} E_f={E_f:.4f}, tau={tau:.4f}, \"\n",
        "          f\"subset={use_subset} (F_eval_fraction={F_eval_fraction})\", flush=True)\n",
        "\n",
        "    kappa_hist, ce_hist, val_accs = [], [], []\n",
        "    D_base_ema = None\n",
        "    prev_kappa_val = None\n",
        "    prev_tau = tau\n",
        "    stalled_count = 0\n",
        "    prev_kappa_zeroish_count = 0\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        epoch_start = torch.cuda.Event(enable_timing=True)\n",
        "        epoch_end = torch.cuda.Event(enable_timing=True)\n",
        "        epoch_start.record()\n",
        "\n",
        "        tau_reasons = []\n",
        "        if fixed_tau:\n",
        "            tau_reasons.append(\"fixed_tau\")\n",
        "\n",
        "        # compute F and E_f\n",
        "        F_vals = compute_F(model, active_loader).clone().requires_grad_(True)\n",
        "        E_f = torch.dot(P_hat, F_vals).item()\n",
        "        varF = float(F_vals.var(unbiased=False).item())\n",
        "\n",
        "        # asymmetric EMA for E_f\n",
        "        if E_f < ef_ema:\n",
        "            beta_down = 0.7\n",
        "            ef_ema = beta_down * ef_ema + (1 - beta_down) * E_f\n",
        "        else:\n",
        "            beta_up = 0.9\n",
        "            ef_ema = beta_up * ef_ema + (1 - beta_up) * E_f\n",
        "\n",
        "        # adapt τ if not fixed\n",
        "        if not fixed_tau:\n",
        "            effective_tau_smooth_lr = tau_smooth_lr\n",
        "            if prev_kappa_val is not None and prev_kappa_val > kappa_shrink_threshold:\n",
        "                effective_tau_smooth_lr = min(1.0, tau_smooth_lr * tau_smooth_lr_boost)\n",
        "                tau_reasons.append(\"accelerated_due_to_large_kappa\")\n",
        "            if prev_kappa_zeroish_count >= 1:\n",
        "                effective_tau_smooth_lr = effective_tau_smooth_lr * 0.1\n",
        "                tau_reasons.append(\"damped_upward_due_to_zero_kappa\")\n",
        "            tau_target = tau_target_multiplier * ef_ema\n",
        "            tau_pre = tau\n",
        "            tau = tau + effective_tau_smooth_lr * (tau_target - tau)\n",
        "            tau = min(tau, ef_ema * 0.99)\n",
        "            if tau > tau_pre + 1e-8:\n",
        "                tau_reasons.append(\"relaxed_upward\")\n",
        "            elif tau < tau_pre - 1e-8:\n",
        "                tau_reasons.append(\"shrunk_toward_target\")\n",
        "\n",
        "        # --- approximate P_star block for provisional τ correction ---\n",
        "        with torch.no_grad():\n",
        "            a = torch.dot(F_vals, P_hat)\n",
        "            b = torch.clamp(torch.sum(F_vals * F_vals), min=1e-12)\n",
        "            h = torch.clamp((tau - a) / b, min=-h_max, max=h_max)  # ✅ clamp\n",
        "            w_vec_approx = P_hat + h * F_vals\n",
        "            P_star_approx = proj_simplex(w_vec_approx)\n",
        "            diff_approx = P_star_approx - P_hat\n",
        "            D_base = 0.5 * torch.sum(diff_approx * diff_approx).detach()\n",
        "\n",
        "            # keep EMA just for logging (no longer drives min_div directly)\n",
        "            if D_base_ema is None:\n",
        "                D_base_ema = D_base\n",
        "            else:\n",
        "                D_base_ema = 0.9 * D_base_ema + 0.1 * D_base\n",
        "\n",
        "            # ✅ min_divergence from variance of F\n",
        "            min_divergence = max(min_div_floor, min_div_from_var_scale * varF)\n",
        "\n",
        "            D_eff = distance_scale * D_base + min_divergence\n",
        "            raw_kappa_approx = (torch.dot(P_star_approx, F_vals) - tau) / D_eff\n",
        "\n",
        "            if raw_kappa_approx.item() < 0 and not fixed_tau:\n",
        "                target_tau = torch.dot(P_star_approx, F_vals).item() - 1e-6\n",
        "                desired_tau = max(base_tau, target_tau)\n",
        "                tau_before = tau\n",
        "                tau_candidate = min(tau * shrink_factor_on_approx_violation, desired_tau)\n",
        "                tau = max(base_tau, tau_candidate)\n",
        "                tau_reasons.append(f\"approx_shrink(factor={shrink_factor_on_approx_violation})\")\n",
        "                if tau < tau_before - 1e-12:\n",
        "                    tau_reasons.append(\"shrunk_due_to_approx_violation\")\n",
        "\n",
        "        # zero-kappa based mild decay of tau\n",
        "        if prev_kappa_zeroish_count >= 2 and not fixed_tau and shrink_tau_on_zero_kappa:\n",
        "            old_tau = tau\n",
        "            tau = max(base_tau, tau * zero_kappa_decay_factor)\n",
        "            if tau < old_tau:\n",
        "                tau_reasons.append(\"zero_kappa_decay\")\n",
        "\n",
        "        # --- compute κ or warmup ---\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        use_rs = ep > warmup_epochs\n",
        "        running_ce = 0.0\n",
        "        raw_kappa_val = None\n",
        "        kappa_scalar_val = 0.0\n",
        "        w = torch.zeros_like(F_vals)\n",
        "        negative_damped_flag = False\n",
        "        zero_kappa_fallback_flag = False\n",
        "\n",
        "        if not use_rs:\n",
        "            # warmup CE with entropy regularization\n",
        "            for x, y, idx in active_loader:\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                logits = model(x)\n",
        "                F_b = ce_element(logits, y)\n",
        "                ce_loss = F_b.mean()\n",
        "                probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "                entropy = - (probs * torch.log(probs + 1e-12)).sum(dim=1).mean()\n",
        "                loss = warmup_ce_weight * ce_loss - entropy_reg_weight * entropy\n",
        "                loss.backward()\n",
        "                running_ce += ce_loss.item() * x.size(0)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "            kappa_scalar_val = 0.0\n",
        "        else:\n",
        "            # RS path (✅ pass variance-based min_div and h_max)\n",
        "            result = KappaFunctionImproved.apply(\n",
        "                F_vals, P_hat, tau,\n",
        "                distance_scale, max(min_div_floor, min_div_from_var_scale * varF),\n",
        "                softplus_temp, neg_scale, h_max\n",
        "            )\n",
        "            if isinstance(result, (tuple, list)) and len(result) == 2:\n",
        "                kappa, raw_kappa = result\n",
        "                raw_kappa_scalar = raw_kappa if raw_kappa.dim() == 0 else raw_kappa.mean()\n",
        "                raw_kappa_val = raw_kappa_scalar.item()\n",
        "            else:\n",
        "                kappa = result\n",
        "                raw_kappa_val = None\n",
        "\n",
        "            kappa_scalar = kappa if kappa.dim() == 0 else kappa.mean()\n",
        "            kappa_scalar_val = kappa_scalar.item()\n",
        "\n",
        "            if kappa_scalar_val < 0:\n",
        "                negative_damped_flag = True\n",
        "                if debug:\n",
        "                    print(f\"[RS] Ep {ep:2d} negative κ={kappa_scalar_val:.3e}; damping by {negative_kappa_damping}\", flush=True)\n",
        "                kappa_to_backprop = kappa_scalar * negative_kappa_damping\n",
        "            else:\n",
        "                kappa_to_backprop = kappa_scalar\n",
        "\n",
        "            kappa_to_backprop.backward()\n",
        "            w = F_vals.grad.detach()\n",
        "            if normalize_w and w.abs().mean() > 0:\n",
        "                w = w / (w.abs().mean() + 1e-8)\n",
        "\n",
        "            if abs(kappa_scalar_val) < 1e-8:\n",
        "                zero_kappa_fallback_flag = True\n",
        "                if shrink_tau_on_zero_kappa and not fixed_tau:\n",
        "                    old_tau = tau\n",
        "                    tau = max(base_tau, 0.9 * E_f)\n",
        "                    if tau < old_tau:\n",
        "                        tau_reasons.append(\"zero_kappa_fallback\")\n",
        "                w = torch.zeros_like(F_vals)\n",
        "\n",
        "            # surrogate + CE + entropy update\n",
        "            optimizer.zero_grad()\n",
        "            for x, y, idx in active_loader:\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                logits = model(x)\n",
        "                F_b = ce_element(logits, y)\n",
        "                surrogate = torch.dot(w[idx], F_b)\n",
        "                ce_mean = F_b.mean()\n",
        "                probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "                entropy = - (probs * torch.log(probs + 1e-12)).sum(dim=1).mean()\n",
        "                loss = damp_surrogate * surrogate + ce_reg_weight * ce_mean - entropy_reg_weight * entropy\n",
        "                loss.backward()\n",
        "                running_ce += ce_mean.item() * x.size(0)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "        # --- update P_hat and exact τ enforcement (✅ clamped h) ---\n",
        "        with torch.no_grad():\n",
        "            a = torch.dot(F_vals, P_hat)\n",
        "            b = torch.clamp(torch.sum(F_vals * F_vals), min=1e-12)\n",
        "            h_for_update = torch.clamp((tau - a) / b, min=-h_max, max=h_max)\n",
        "            w_vec = P_hat + h_for_update * F_vals\n",
        "            P_star = proj_simplex(w_vec)\n",
        "            diff = P_star - P_hat\n",
        "            D_base_exact = 0.5 * torch.sum(diff * diff).item()\n",
        "\n",
        "            worst_case_exp = torch.dot(P_star, F_vals).item()\n",
        "            if worst_case_exp - 1e-6 < tau and not fixed_tau:\n",
        "                new_tau = max(base_tau, worst_case_exp - 1e-6)\n",
        "                if new_tau < tau:\n",
        "                    tau_reasons.append(\"shrunk_due_to_exact_violation\")\n",
        "                    tau = new_tau\n",
        "\n",
        "            P_hat_new = (1 - P_hat_momentum) * P_hat + P_hat_momentum * P_star\n",
        "            P_hat.copy_(P_hat_new / P_hat_new.sum())\n",
        "\n",
        "        # timing\n",
        "        epoch_end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        elapsed_ms = epoch_start.elapsed_time(epoch_end)\n",
        "\n",
        "        # --- exact snapshot for diagnostics (✅ clamped h, var-based min_div) ---\n",
        "        with torch.no_grad():\n",
        "            a_final = torch.dot(F_vals, P_hat)\n",
        "            b_final = torch.clamp(torch.sum(F_vals * F_vals), min=1e-12)\n",
        "            h_final = torch.clamp((tau - a_final) / b_final, min=-h_max, max=h_max)\n",
        "            w_vec_final = P_hat + h_final * F_vals\n",
        "            P_star_final = proj_simplex(w_vec_final)\n",
        "            diff_final = P_star_final - P_hat\n",
        "            D_base_final = 0.5 * torch.sum(diff_final * diff_final)\n",
        "            min_div_final = max(min_div_floor, min_div_from_var_scale * varF)\n",
        "            D_eff_final = distance_scale * D_base_final + min_div_final\n",
        "            raw_kappa_exact_final = (torch.dot(P_star_final, F_vals) - tau) / D_eff_final\n",
        "\n",
        "        ce_avg = running_ce / N\n",
        "        numerator = E_f - tau\n",
        "        h_val = h_final.item() if isinstance(h_final, torch.Tensor) else h_final\n",
        "        D_val = D_base_exact\n",
        "        reason_str = \";\".join(tau_reasons) if tau_reasons else \"none\"\n",
        "\n",
        "        if raw_kappa_val is not None:\n",
        "            print(f\"[RS] Ep {ep:2d} κ={kappa_scalar_val:.3e} raw_kappa={raw_kappa_val:.3e} \"\n",
        "                  f\"E_f={E_f:.4f} num={numerator:.4e} h={h_val:.3e} D={D_val:.3e} \"\n",
        "                  f\"τ={tau:.4f} CE={ce_avg:.4f} epoch_time={elapsed_ms/1000:.2f}s\", flush=True)\n",
        "        else:\n",
        "            print(f\"[RS] Ep {ep:2d} κ={kappa_scalar_val:.3e} raw_kappa_exact={raw_kappa_exact_final:.3e} \"\n",
        "                  f\"E_f={E_f:.4f} num={numerator:.4e} h={h_val:.3e} D={D_val:.3e} \"\n",
        "                  f\"τ={tau:.4f} CE={ce_avg:.4f} epoch_time={elapsed_ms/1000:.2f}s\", flush=True)\n",
        "\n",
        "        print(f\"[debug] E_f={E_f:.4f} tau={tau:.4f} reasons={reason_str} \"\n",
        "              f\"Var(F)={varF:.4e} D_base={float(D_base_final):.4e} D_eff={float(D_eff_final):.4e} \"\n",
        "              f\"raw_kappa_exact={float(raw_kappa_exact_final):.4e} raw_kappa_approx={float(raw_kappa_approx):.4e}\",\n",
        "              flush=True)\n",
        "\n",
        "        kappa_hist.append(kappa_scalar_val)\n",
        "        ce_hist.append(ce_avg)\n",
        "\n",
        "        # validation\n",
        "        if val_loader is not None and (ep % val_interval == 0 or ep == 1):\n",
        "            val_acc = evaluate_with_diagnostics(model, val_loader)\n",
        "            val_accs.append((ep, val_acc))\n",
        "\n",
        "        # update zero-kappa tracker\n",
        "        kappa_zeroish = abs(kappa_scalar_val) < 1e-8\n",
        "        if kappa_zeroish:\n",
        "            prev_kappa_zeroish_count += 1\n",
        "        else:\n",
        "            prev_kappa_zeroish_count = 0\n",
        "\n",
        "        # early stopping\n",
        "        tau_stable = abs(tau - prev_tau) < 1e-4\n",
        "        if ep >= min_epochs_before_early_stop and tau_stable and kappa_zeroish:\n",
        "            print(f\"[RS] Early stopping at epoch {ep} because τ stabilized and κ≈0 for {early_stop_patience} epochs.\", flush=True)\n",
        "            break\n",
        "\n",
        "        prev_kappa_val = kappa_scalar_val\n",
        "        prev_tau = tau\n",
        "\n",
        "    return kappa_hist, ce_hist, val_accs\n"
      ],
      "metadata": {
        "id": "mMwbqn6xmgEu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 5 ─────────────────────────────────────────────\n",
        "\n",
        "model_std = SimpleCNN().to(device)\n",
        "model_rs = SimpleCNN().to(device)\n",
        "model_sam = SimpleCNN().to(device)\n",
        "\n",
        "print(\"\\nStarting RS training (improved)…\", flush=True)\n",
        "kappa_list, train_losses_rs, val_history = train_rs(\n",
        "    model_rs,\n",
        "    rs_loader,\n",
        "    epochs=80,\n",
        "    lr=5e-5,                          # slightly larger learning rate\n",
        "    initial_tau_multiplier=0.3,       # start tau lower relative to E_f\n",
        "    tau_target_multiplier=0.6,        # target stays under E_f\n",
        "    tau_smooth_lr=0.1,                # slower smoothing, less jitter\n",
        "    P_hat_momentum=0.2,\n",
        "    damp_surrogate=0.1,\n",
        "    ce_reg_weight=1.0,                # stronger supervised signal\n",
        "    warmup_ce_weight=1.0,\n",
        "    entropy_reg_weight=0.05,          # stronger entropy regularization to avoid collapse\n",
        "    use_subset=False,\n",
        "    subset_size=4096,                 # larger subset to reduce sampling bias\n",
        "    normalize_w=False,\n",
        "    debug=True,\n",
        "    base_tau=0.1,\n",
        "    distance_scale=1.0,\n",
        "    softplus_temp=1.0,               # sharper kappa activation\n",
        "    warmup_epochs=10,                # longer pure CE warmup\n",
        "    start_at_base=True,\n",
        "    fixed_tau=False,\n",
        "    val_loader=val_loader,\n",
        "    val_interval=5,\n",
        "    early_stop_patience=5,\n",
        "    min_epochs_before_early_stop=10,\n",
        "    negative_kappa_damping=0.2,       # gentler handling of negative kappa\n",
        "    shrink_factor_on_approx_violation=0.85,  # less aggressive tau shrink\n",
        "    zero_kappa_decay_factor=0.98,     # milder decay when kappa≈0\n",
        "    shrink_tau_on_zero_kappa=False,    # allow tau to recover upward if κ=0\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nStarting SAM training…\", flush=True)\n",
        "train_losses_sam = train_sam(model_sam, train_loader, epochs=40, lr=2e-5, rho=0.05)\n",
        "\n",
        "print(\"Starting SGD training…\", flush=True)\n",
        "train_losses_std = train_standard(model_std, train_loader, epochs=40, lr=2e-5)\n",
        "\n",
        "# Evaluate\n",
        "acc_std = evaluate(model_std, val_loader)\n",
        "acc_rs = evaluate(model_rs, val_loader)\n",
        "print(f\"RS Validation Accuracy: {acc_rs}\")\n",
        "acc_sam = evaluate(model_sam, val_loader)\n",
        "print(f\"\\nValidation acc · SGD: {acc_std:.4f}, RS: {acc_rs:.4f}, SAM: {acc_sam:.4f}\", flush=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtnINZYp9_qh",
        "outputId": "4aa9bbea-6c0f-4b26-9fa1-f2a54ffed416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RS training (improved)…\n",
            "[RS] Computing F on 100% of training data (302436/302436) ~591 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rF (init):   0%|          | 0/591 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(train_losses_std, label=\"SGD\")\n",
        "plt.plot(train_losses_rs, label=\"RS\")\n",
        "plt.plot(train_losses_sam, label=\"SAM\")\n",
        "plt.legend()\n",
        "plt.title(\"Train CE / κ comparison\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(kappa_list, label=\"RS κ\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"κ\")\n",
        "plt.title(\"RS κ over time\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kMX3Otm0rD_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1) checkpoint directory in Drive\n",
        "save_dir = '/content/drive/My Drive/camelyon17_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 2) collect them\n",
        "models = {\n",
        "    'baseline_sgd': model_std,\n",
        "    'rs_on_data':   model_rs,\n",
        "    'sam_model':    model_sam,\n",
        "}\n",
        "\n",
        "# 3) save\n",
        "for name, mdl in models.items():\n",
        "    fn = f'{name}.pth'\n",
        "    path = os.path.join(save_dir, fn)\n",
        "    torch.save(mdl.state_dict(), path)\n",
        "    print(f'Saved {name} weights to {path}')"
      ],
      "metadata": {
        "id": "TzLX_59XFTHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "mWk8EWMM35_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UoG9QuKq359J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b04JQtuv356v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}